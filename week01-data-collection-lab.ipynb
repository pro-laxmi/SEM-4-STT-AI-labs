{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgwI4zi7xhb7"
      },
      "source": [
        "# Week 1 Lab: Data Collection for Machine Learning\n",
        "\n",
        "**CS 203: Software Tools and Techniques for AI**\n",
        "\n",
        "---\n",
        "\n",
        "## Lab Overview\n",
        "\n",
        "In this lab, you will learn to collect data from the web using:\n",
        "\n",
        "1. **HTTP fundamentals** - Understanding how the web works\n",
        "2. **curl** - Command-line HTTP client\n",
        "3. **Python requests** - Programmatic API calls\n",
        "4. **BeautifulSoup** - Web scraping when APIs don't exist\n",
        "\n",
        "**Goal**: Build a movie data collection pipeline for Netflix-style movie prediction.\n",
        "\n",
        "---\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's install and import the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0_bo7tiWxhb9"
      },
      "outputs": [],
      "source": [
        "# Install required packages (uncomment if needed)\n",
        "# !pip install requests beautifulsoup4 pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-dh49UZxhb-",
        "outputId": "a1cfa44e-0911-493e-ff86-673861eae8de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All imports successful!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "\n",
        "print(\"All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBsAcgLFxhb-"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 1: HTTP Fundamentals\n",
        "\n",
        "Before we start collecting data, we need to understand how the web works.\n",
        "\n",
        "## 1.1 Understanding URLs\n",
        "\n",
        "A URL (Uniform Resource Locator) has several components:\n",
        "\n",
        "```\n",
        "https://api.omdbapi.com:443/v1/movies?t=Inception&y=2010#details\n",
        "â””â”€â”¬â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â””â”¬â”€â”˜â””â”€â”€â”¬â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”¬â”€â”€â”€â”˜\n",
        "  â”‚           â”‚         â”‚      â”‚              â”‚             â”‚\n",
        "Protocol    Host      Port   Path          Query        Fragment\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hamTOalxhb-"
      },
      "source": [
        "### Question 1.1 (Solved): Parse a URL\n",
        "\n",
        "Use Python's `urllib.parse` to break down a URL into its components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIJx8ADYxhb_",
        "outputId": "6e37050f-b3cd-4b44-8fce-c559186a2724"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scheme (protocol): https\n",
            "Host (domain): api.omdbapi.com\n",
            "Path: /\n",
            "Query string: apikey=demo&t=Inception&y=2010\n",
            "Fragment: details\n",
            "\n",
            "Parsed parameters: {'apikey': ['demo'], 't': ['Inception'], 'y': ['2010']}\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "url = \"https://api.omdbapi.com/?apikey=demo&t=Inception&y=2010#details\"\n",
        "\n",
        "parsed = urlparse(url)\n",
        "\n",
        "print(f\"Scheme (protocol): {parsed.scheme}\")\n",
        "print(f\"Host (domain): {parsed.netloc}\")\n",
        "print(f\"Path: {parsed.path}\")\n",
        "print(f\"Query string: {parsed.query}\")\n",
        "print(f\"Fragment: {parsed.fragment}\")\n",
        "\n",
        "# Parse query parameters into a dictionary\n",
        "params = parse_qs(parsed.query)\n",
        "print(f\"\\nParsed parameters: {params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ediT2Mwdxhb_"
      },
      "source": [
        "### Question 1.2: Parse a Different URL\n",
        "\n",
        "Parse the following GitHub API URL and extract:\n",
        "1. The host\n",
        "2. The path\n",
        "3. All query parameters as a dictionary\n",
        "\n",
        "URL: `https://api.github.com/search/repositories?q=machine+learning&sort=stars&order=desc`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxooeI-Txhb_",
        "outputId": "f618b076-96b9-4f49-b911-fda994db4c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Host of the URL: api.github.com\n",
            "path of the URL: /search/repositories\n",
            "https\n",
            "\n",
            "\n",
            "q=machine+learning&sort=stars&order=desc\n",
            "Params of the URL: {'q': ['machine learning'], 'sort': ['stars'], 'order': ['desc']}\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "url = \"https://api.github.com/search/repositories?q=machine+learning&sort=stars&order=desc\"\n",
        "\n",
        "# Parse the URL\n",
        "parsed_url = urlparse(url)\n",
        "# Print the host\n",
        "print(f\"Host of the URL: {parsed_url.netloc}\")  # What is the difference between netloc and hostname I think both are the same\n",
        "# Print the path\n",
        "print(f\"path of the URL: {parsed_url.path}\")\n",
        "# Print the query parameters as a dictionary\n",
        "print(parsed_url.scheme)\n",
        "print(parsed_url.params)\n",
        "print(parsed_url.fragment)\n",
        "print(parsed_url.query)\n",
        "\n",
        "params = parse_qs(parsed_url.query)\n",
        "print(f\"Params of the URL: {params}\")\n",
        "# print(parsed_url.encode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y8r2Oadxhb_"
      },
      "source": [
        "---\n",
        "\n",
        "## 1.2 HTTP Status Codes\n",
        "\n",
        "HTTP status codes tell you what happened with your request:\n",
        "\n",
        "| Range | Category | Common Examples |\n",
        "|-------|----------|----------------|\n",
        "| 2xx | Success | 200 OK, 201 Created |\n",
        "| 3xx | Redirect | 301 Moved, 302 Found |\n",
        "| 4xx | Client Error | 400 Bad Request, 401 Unauthorized, 404 Not Found |\n",
        "| 5xx | Server Error | 500 Internal Error, 503 Service Unavailable |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vHQhHrkxhb_"
      },
      "source": [
        "### Question 1.3: Match Status Codes\n",
        "\n",
        "Match each scenario to the most likely HTTP status code:\n",
        "\n",
        "1. You requested a movie that doesn't exist in the database\n",
        "2. You made too many requests and hit the rate limit\n",
        "3. Your API key is invalid\n",
        "4. The request was successful and data was returned\n",
        "5. The server crashed while processing your request\n",
        "\n",
        "Status codes to choose from: `200`, `401`, `404`, `429`, `500`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj3lT--HxhcA",
        "outputId": "11e0bf50-7fa5-4773-e85f-82b8df485b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'movie_not_found': 404, 'rate_limited': 429, 'invalid_api_key': 401, 'success': 200, 'server_crashed': 500}\n"
          ]
        }
      ],
      "source": [
        "# YOUR ANSWERS HERE\n",
        "answers = {\n",
        "    \"movie_not_found\": 404,      # Replace None with the status code\n",
        "    \"rate_limited\": 429,\n",
        "    \"invalid_api_key\": 401,\n",
        "    \"success\": 200,\n",
        "    \"server_crashed\": 500\n",
        "}\n",
        "\n",
        "print(answers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sa8EzMCxhcA"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 2: Making Requests with `curl`\n",
        "\n",
        "`curl` is a command-line tool for making HTTP requests. It's essential for quick testing.\n",
        "\n",
        "## 2.1 Basic curl Commands\n",
        "\n",
        "You can run shell commands in Jupyter using `!` prefix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IUsg2PYxhcA"
      },
      "source": [
        "### Question 2.1 (Solved): Your First API Call\n",
        "\n",
        "Let's call a simple public API that requires no authentication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8u2ZDWGxhcA",
        "outputId": "d2203ad3-22af-453f-a9e6-c585b3d45266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"userId\": 1,\n",
            "  \"id\": 1,\n",
            "  \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\",\n",
            "  \"body\": \"quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "# JSONPlaceholder is a free fake API for testing\n",
        "!curl -s \"https://jsonplaceholder.typicode.com/posts/1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlhNEwrDxhcA"
      },
      "source": [
        "### Question 2.2: Pretty Print with jq\n",
        "\n",
        "The output above is hard to read. Use `jq` to format it nicely.\n",
        "\n",
        "**Hint**: Pipe the curl output to jq: `curl ... | jq .`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0pxWK4J4s6g",
        "outputId": "7ea777f3-8aad-463a-a0f4-ccb9ee305673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Usage: curl [options...] <url>\n",
            " -d, --data <data>           HTTP POST data\n",
            " -f, --fail                  Fail fast with no output on HTTP errors\n",
            " -h, --help <subject>        Get help for commands\n",
            " -o, --output <file>         Write to file instead of stdout\n",
            " -O, --remote-name           Write output to file named as remote file\n",
            " -i, --show-headers          Show response headers in output\n",
            " -s, --silent                Silent mode\n",
            " -T, --upload-file <file>    Transfer local FILE to destination\n",
            " -u, --user <user:password>  Server user and password\n",
            " -A, --user-agent <name>     Send User-Agent <name> to server\n",
            " -v, --verbose               Make the operation more talkative\n",
            " -V, --version               Show version number and quit\n",
            "\n",
            "This is not the full help; this menu is split into categories.\n",
            "Use \"--help category\" to get an overview of all categories, which are:\n",
            "auth, connection, curl, deprecated, dns, file, ftp, global, http, imap, ldap, \n",
            "output, pop3, post, proxy, scp, sftp, smtp, ssh, telnet, tftp, timeout, tls, \n",
            "upload, verbose.\n",
            "Use \"--help all\" to list all options\n"
          ]
        }
      ],
      "source": [
        "!curl --help"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_-Y16565hTx"
      },
      "source": [
        "Exploring different functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea9EYpwu49j9",
        "outputId": "c656dd97-9862-438c-9929-bdc922b76d5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'jq' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!curl -d \"https://jsonplaceholder.typicode.com/posts/1\" | jq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4OXpK3c5CWL",
        "outputId": "4f411577-154b-453b-9b05-f9ff0b2a1afb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'jq' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!curl -f \"https://jsonplaceholder.typicode.com/posts/1\" | jq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84qOOFay5Hnn",
        "outputId": "5fdb216e-4ac6-4283-9bdd-ba79a064b91e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'jq' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!curl -i \"https://jsonplaceholder.typicode.com/posts/1\" | jq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1oJNKTa5OQk",
        "outputId": "a2ad7a74-87e9-4610-a5d0-0f45f55fc94c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'jq' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!curl -O  \"https://jsonplaceholder.typicode.com/posts/1\" | jq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E1Wy61a5YAt",
        "outputId": "aaa9518b-9260-4549-cb74-f941126de3a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'jq' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!curl -s \"https://jsonplaceholder.typicode.com/posts/1\" | jq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGqgJbOHxhcA",
        "outputId": "8ec736d8-45be-4e46-938e-a6a0be483632"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'jq' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Fetch the same post but format the output with jq\n",
        "!curl -v \"https://jsonplaceholder.typicode.com/posts/1\" | jq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7PJOZA8xhcA"
      },
      "source": [
        "### Question 2.3: Extract Specific Fields with jq\n",
        "\n",
        "Fetch all posts from `https://jsonplaceholder.typicode.com/posts` and extract only the `title` field from each post.\n",
        "\n",
        "**Hint**: Use `jq '.[].title'` to get the title from each element in the array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5a5M89ExhcA",
        "outputId": "7ce9f88e-6208-49e8-c291-ce5c7d09cc9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'jq' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "!curl -s \"https://jsonplaceholder.typicode.com/posts\" | jq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIHHVz1u6CKx"
      },
      "source": [
        "We want to get title from each parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNRZx2Me6INJ",
        "outputId": "68e96cbc-8ef7-4319-fdd9-a9a202f7868f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'jq' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!curl -s \"https://jsonplaceholder.typicode.com/posts\" | jq '.[].title'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gmB-sArxhcA"
      },
      "source": [
        "### Question 2.4: View Response Headers\n",
        "\n",
        "Use the `-I` flag to fetch only the response headers (no body) from:\n",
        "`https://api.github.com`\n",
        "\n",
        "What is the value of the `X-RateLimit-Limit` header?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a65reybxhcA",
        "outputId": "f9904b6b-9bd6-4d83-a5fe-530a20cfb988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP/1.1 403 rate limit exceeded\n",
            "Date: Sat, 10 Jan 2026 08:55:19 GMT\n",
            "Server: Varnish\n",
            "Strict-Transport-Security: max-age=31536000; includeSubdomains; preload\n",
            "X-Content-Type-Options: nosniff\n",
            "X-Frame-Options: deny\n",
            "X-XSS-Protection: 1; mode=block\n",
            "Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'\n",
            "Access-Control-Allow-Origin: *\n",
            "Access-Control-Expose-Headers: ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-RateLimit-Used, X-RateLimit-Resource, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset\n",
            "Content-Type: application/json; charset=utf-8\n",
            "Referrer-Policy: origin-when-cross-origin, strict-origin-when-cross-origin\n",
            "X-GitHub-Media-Type: github.v3; format=json\n",
            "X-RateLimit-Limit: 60\n",
            "X-RateLimit-Remaining: 0\n",
            "X-RateLimit-Reset: 1768037256\n",
            "X-RateLimit-Resource: core\n",
            "X-RateLimit-Used: 60\n",
            "Content-Length: 279\n",
            "X-GitHub-Request-Id: DC0B:267088:FE50A0:12DE783:696213F7\n",
            "\n",
            "{\"message\":\"API rate limit exceeded for 14.139.98.103. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\",\"documentation_url\":\"https://docs.github.com/rest/overview/resources-in-the-rest-api#rate-limiting\"}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100   279  100   279    0     0    915      0 --:--:-- --:--:-- --:--:--   920\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "!curl -i \"https://api.github.com\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruOVRUM18CXE"
      },
      "source": [
        "Code to get a specific tag from the header"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxOquV6y8JcG",
        "outputId": "2e7f61a2-ffbe-4321-928b-dbf8fa6a3ed9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'grep' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!curl -I -s https://api.github.com | grep -i x-ratelimit-limit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uqLaMIp7frW",
        "outputId": "9ba9af2b-7306-4800-bef1-1f2426f5e812"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'grep' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!curl -I -s https://api.github.com | grep -i ratelimit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD8JKm32xhcA"
      },
      "source": [
        "### Question 2.5: Add Custom Headers\n",
        "\n",
        "Make a request to `https://httpbin.org/headers` with the following custom headers:\n",
        "- `User-Agent: CS203-Lab/1.0`\n",
        "- `Accept: application/json`\n",
        "\n",
        "**Hint**: Use `-H \"Header-Name: value\"` for each header."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oAwCSsZxhcA",
        "outputId": "f25a877a-2f67-4ba9-c714-a6424a0cd5bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"headers\": {\n",
            "    \"Accept\": \"application/json\", \n",
            "    \"Host\": \"httpbin.org\", \n",
            "    \"User-Agent\": \"CS203-Lab/1.0\", \n",
            "    \"X-Amzn-Trace-Id\": \"Root=1-696213f9-3ce7c8b86f4067cd2a71d8ad\"\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100   188  100   188    0     0    109      0  0:00:01  0:00:01 --:--:--   109\n"
          ]
        }
      ],
      "source": [
        "# If I want to do multiple oprations on one line I can do something like this\n",
        "!curl -H \"User-Agent: CS203-Lab/1.0\" -H \"Accept: application/json\" \"https://httpbin.org/headers\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2triFW_xhcB"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 3: Python `requests` Library\n",
        "\n",
        "While `curl` is great for testing, we need Python for automation.\n",
        "\n",
        "## 3.1 Basic GET Requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqbQGphdxhcB"
      },
      "source": [
        "### Question 3.1 (Solved): Simple GET Request\n",
        "\n",
        "Make a GET request and inspect the response object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwitflOwxhcB",
        "outputId": "486318db-2b11-45e9-8591-1959eff1ae75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Status Code: 200\n",
            "Content-Type: application/json; charset=utf-8\n",
            "Response OK: True\n",
            "\n",
            "JSON Data:\n",
            "{'userId': 1, 'id': 2, 'title': 'qui est esse', 'body': 'est rerum tempore vitae\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\nfugiat blanditiis voluptate porro vel nihil molestiae ut reiciendis\\nqui aperiam non debitis possimus qui neque nisi nulla'}\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "\n",
        "response = requests.get(\"https://jsonplaceholder.typicode.com/posts/2\")\n",
        "\n",
        "print(f\"Status Code: {response.status_code}\")\n",
        "print(f\"Content-Type: {response.headers['Content-Type']}\")\n",
        "print(f\"Response OK: {response.ok}\")\n",
        "print(f\"\\nJSON Data:\")\n",
        "print(response.json())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39K9WbcixhcB"
      },
      "source": [
        "### Question 3.2: Fetch Multiple Posts\n",
        "\n",
        "Fetch posts from `https://jsonplaceholder.typicode.com/posts` and:\n",
        "1. Print the total number of posts\n",
        "2. Print the titles of the first 5 posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIzruhODxhcB",
        "outputId": "d0cd44ef-0ae1-4d23-a999-bad67abe327b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total no of posts: 100\n",
            "First five titles are here:\n",
            "Title 1: sunt aut facere repellat provident occaecati excepturi optio reprehenderit\n",
            "Title 2: qui est esse\n",
            "Title 3: ea molestias quasi exercitationem repellat qui ipsa sit aut\n",
            "Title 4: eum et est occaecati\n",
            "Title 5: nesciunt quas odio\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "response = requests.get(\"https://jsonplaceholder.typicode.com/posts\")\n",
        "print(f'Total no of posts: {len(response.json())}')\n",
        "print(f'First five titles are here:')\n",
        "for i in range(5):\n",
        "  print(f\"Title {i+1}: {response.json()[i]['title']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_9uZshlxhcB"
      },
      "source": [
        "### Question 3.3 (Solved): Using Query Parameters\n",
        "\n",
        "The proper way to add query parameters is using the `params` argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zpLhDLDbxhcB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User 1 has 10 posts\n",
            "\n",
            "Actual URL used: https://jsonplaceholder.typicode.com/posts?userId=10\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "\n",
        "# Bad way (manual string building)\n",
        "# url = \"https://jsonplaceholder.typicode.com/posts?userId=1\"\n",
        "\n",
        "# Good way (using params)\n",
        "response = requests.get(\n",
        "    \"https://jsonplaceholder.typicode.com/posts\",\n",
        "    params={\"userId\": 10}\n",
        ")\n",
        "\n",
        "posts = response.json()\n",
        "print(f\"User 1 has {len(posts)} posts\")\n",
        "print(f\"\\nActual URL used: {response.url}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn-S2nhSxhcB"
      },
      "source": [
        "### Question 3.4: Filter Posts by User\n",
        "\n",
        "Fetch all posts by user 5 and user 7. Compare how many posts each user has.\n",
        "\n",
        "**Hint**: Make two separate requests with different `userId` values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SRQi4Q94xhcB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Posts by user 5 is: 10, and by user 7 is: 10\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "response_user_5 = requests.get(\n",
        "    \"https://jsonplaceholder.typicode.com/posts\",\n",
        "    params={\"userId\": 5}\n",
        ")\n",
        "posts_5 = response_user_5.json()\n",
        "response_user_7 = requests.get(\n",
        "    \"https://jsonplaceholder.typicode.com/posts\",\n",
        "    params={\"userId\": 7}\n",
        ")\n",
        "posts_7 = response_user_7.json()\n",
        "print(f\"Posts by user 5 is: {len(posts_5)}, and by user 7 is: {len(posts_7)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgDvEWLRxhcB"
      },
      "source": [
        "---\n",
        "\n",
        "## 3.2 Working with Real APIs\n",
        "\n",
        "Let's work with some real-world APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aoXzo0CxhcB"
      },
      "source": [
        "### Question 3.5 (Solved): GitHub API - Public Repositories\n",
        "\n",
        "The GitHub API is free to use (with rate limits) and doesn't require authentication for public data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token exists: True\n",
            "200\n",
            "{'login': 'pro-laxmi', 'id': 180728857, 'node_id': 'U_kgDOCsW0GQ', 'avatar_url': 'https://avatars.githubusercontent.com/u/180728857?v=4', 'gravatar_id': '', 'url': 'https://api.github.com/users/pro-laxmi', 'html_url': 'https://github.com/pro-laxmi', 'followers_url': 'https://api.github.com/users/pro-laxmi/followers', 'following_url': 'https://api.github.com/users/pro-laxmi/following{/other_user}', 'gists_url': 'https://api.github.com/users/pro-laxmi/gists{/gist_id}', 'starred_url': 'https://api.github.com/users/pro-laxmi/starred{/owner}{/repo}', 'subscriptions_url': 'https://api.github.com/users/pro-laxmi/subscriptions', 'organizations_url': 'https://api.github.com/users/pro-laxmi/orgs', 'repos_url': 'https://api.github.com/users/pro-laxmi/repos', 'events_url': 'https://api.github.com/users/pro-laxmi/events{/privacy}', 'received_events_url': 'https://api.github.com/users/pro-laxmi/received_events', 'type': 'User', 'user_view_type': 'public', 'site_admin': False, 'name': 'Laxmidhar Panda', 'company': None, 'blog': 'https://pro-laxmi.github.io/Portfolio', 'location': None, 'email': None, 'hireable': None, 'bio': 'CSE @ IITGandhinagar', 'twitter_username': None, 'notification_email': None, 'public_repos': 15, 'public_gists': 0, 'followers': 4, 'following': 1, 'created_at': '2024-09-07T05:05:45Z', 'updated_at': '2026-01-04T07:19:24Z'}\n"
          ]
        }
      ],
      "source": [
        "token = \"YOUR_TOKEN_HERE\"\n",
        "print(\"Token exists:\", token is not None)\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"token {token}\",\n",
        "    \"Accept\": \"application/vnd.github.v3+json\"\n",
        "}\n",
        "\n",
        "r = requests.get(\"https://api.github.com/user\", headers=headers)\n",
        "print(r.status_code)\n",
        "print(r.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "KDoLZaVWxhcB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository: pandas-dev/pandas\n",
            "Description: Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more\n",
            "Stars: 47,520\n",
            "Forks: 19,492\n",
            "Language: Python\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "\n",
        "# Fetch information about a popular repository\n",
        "headers = {\n",
        "    \"Authorization\": f\"token {token}\",\n",
        "    \"Accept\": \"application/vnd.github.v3+json\"\n",
        "}\n",
        "response = requests.get(\n",
        "    \"https://api.github.com/repos/pandas-dev/pandas\",\n",
        "    headers=headers\n",
        ")\n",
        "\n",
        "if response.ok:\n",
        "    repo = response.json()\n",
        "    print(f\"Repository: {repo['full_name']}\")\n",
        "    print(f\"Description: {repo['description']}\")\n",
        "    print(f\"Stars: {repo['stargazers_count']:,}\")\n",
        "    print(f\"Forks: {repo['forks_count']:,}\")\n",
        "    print(f\"Language: {repo['language']}\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTTP/1.1 403 rate limit exceeded\n",
            "Date: Sat, 10 Jan 2026 09:08:00 GMT\n",
            "Server: Varnish\n",
            "Strict-Transport-Security: max-age=31536000; includeSubdomains; preload\n",
            "X-Content-Type-Options: nosniff\n",
            "X-Frame-Options: deny\n",
            "X-XSS-Protection: 1; mode=block\n",
            "Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'\n",
            "Access-Control-Allow-Origin: *\n",
            "Access-Control-Expose-Headers: ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Reset, X-RateLimit-Used, X-RateLimit-Resource, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset\n",
            "Content-Type: application/json; charset=utf-8\n",
            "Referrer-Policy: origin-when-cross-origin, strict-origin-when-cross-origin\n",
            "X-GitHub-Media-Type: github.v3; format=json\n",
            "X-RateLimit-Limit: 60\n",
            "X-RateLimit-Remaining: 0\n",
            "X-RateLimit-Reset: 1768037256\n",
            "X-RateLimit-Resource: core\n",
            "X-RateLimit-Used: 60\n",
            "Content-Length: 279\n",
            "X-GitHub-Request-Id: C88B:15FCE6:FC307E:12C2206:696216F0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!curl -I -s https://api.github.com/repos/pandas-dev/pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtEi6MBhxhcB"
      },
      "source": [
        "### Question 3.6: Compare Popular ML Libraries\n",
        "\n",
        "Fetch information about these ML-related repositories and create a comparison table:\n",
        "- `scikit-learn/scikit-learn`\n",
        "- `pytorch/pytorch`\n",
        "- `tensorflow/tensorflow`\n",
        "\n",
        "Show: name, stars, forks, and primary language.\n",
        "\n",
        "**Hint**: Loop through the repos and collect data into a list of dictionaries, then create a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "o4zL-WVJxhcB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository: scikit-learn/scikit-learn\n",
            "Stars: 64,573\n",
            "Forks: 26,585\n",
            "Language: Python\n",
            "----------------------------------------\n",
            "Repository: pytorch/pytorch\n",
            "Stars: 96,481\n",
            "Forks: 26,473\n",
            "Language: Python\n",
            "----------------------------------------\n",
            "Repository: tensorflow/tensorflow\n",
            "Stars: 193,273\n",
            "Forks: 75,148\n",
            "Language: C++\n",
            "----------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>repo</th>\n",
              "      <th>stars</th>\n",
              "      <th>forks</th>\n",
              "      <th>language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>scikit-learn/scikit-learn</td>\n",
              "      <td>64573</td>\n",
              "      <td>26585</td>\n",
              "      <td>Python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>pytorch/pytorch</td>\n",
              "      <td>96481</td>\n",
              "      <td>26473</td>\n",
              "      <td>Python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tensorflow/tensorflow</td>\n",
              "      <td>193273</td>\n",
              "      <td>75148</td>\n",
              "      <td>C++</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        repo   stars  forks language\n",
              "0  scikit-learn/scikit-learn   64573  26585   Python\n",
              "1            pytorch/pytorch   96481  26473   Python\n",
              "2      tensorflow/tensorflow  193273  75148      C++"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "repos = [\n",
        "    \"scikit-learn/scikit-learn\",\n",
        "    \"pytorch/pytorch\",\n",
        "    \"tensorflow/tensorflow\"\n",
        "]\n",
        "\n",
        "all_repos_data = []\n",
        "# Fetch data for each repo\n",
        "for repo in repos:\n",
        "    response = requests.get(\n",
        "        f\"https://api.github.com/repos/{repo}\",\n",
        "        headers=headers\n",
        "    )\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "        all_repos_data.append({'repo': data['full_name'], 'stars': data['stargazers_count'], 'forks': data['forks_count'], 'language': data['language']})\n",
        "        print(f\"Repository: {data['full_name']}\")\n",
        "        print(f\"Stars: {data['stargazers_count']:,}\")\n",
        "        print(f\"Forks: {data['forks_count']:,}\")\n",
        "        print(f\"Language: {data['language']}\")\n",
        "        print(\"-\" * 40)\n",
        "    else:\n",
        "        print(f\"Error fetching {repo}: {response.status_code}\")\n",
        "# Create a DataFrame\n",
        "repo_data = pd.DataFrame(all_repos_data)\n",
        "\n",
        "# Display the comparison\n",
        "repo_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFz2atvdxhcB"
      },
      "source": [
        "### Question 3.7: Search GitHub Repositories\n",
        "\n",
        "Use the GitHub search API to find the top 10 most starred repositories with \"machine learning\" in their description.\n",
        "\n",
        "API endpoint: `https://api.github.com/search/repositories`\n",
        "\n",
        "Parameters:\n",
        "- `q`: search query (e.g., \"machine learning\")\n",
        "- `sort`: \"stars\"\n",
        "- `order`: \"desc\"\n",
        "- `per_page`: 10\n",
        "\n",
        "Print the name and star count of each repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ufUsVjFpxhcB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the repo: tensorflow and the star count is: 193273\n",
            "Name of the repo: transformers and the star count is: 154836\n",
            "Name of the repo: ML-For-Beginners and the star count is: 82967\n",
            "Name of the repo: funNLP and the star count is: 78348\n",
            "Name of the repo: awesome-machine-learning and the star count is: 71266\n",
            "Name of the repo: scikit-learn and the star count is: 64573\n",
            "Name of the repo: gradio and the star count is: 41247\n",
            "Name of the repo: C-Plus-Plus and the star count is: 33658\n",
            "Name of the repo: netron and the star count is: 32157\n",
            "Name of the repo: 500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code and the star count is: 30752\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "url = \"https://api.github.com/search/repositories\"\n",
        "params = {\n",
        "    'q' : \"machine learning\",\n",
        "    'sort' : \"stars\",\n",
        "    'order' : \"desc\",\n",
        "    'per_page' : 10\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers, params=params)\n",
        "data = response.json()\n",
        "all_repos_data = []\n",
        "for item in data['items']:\n",
        "    print(f'Name of the repo: {item['name']} and the star count is: {item['stargazers_count']}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv6tCm0MxhcC"
      },
      "source": [
        "---\n",
        "\n",
        "## 3.3 Error Handling\n",
        "\n",
        "Real-world APIs fail. We need to handle errors gracefully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COuzDmqJxhcE"
      },
      "source": [
        "### Question 3.8 (Solved): Handling HTTP Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "o39xjy8VxhcE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Valid URL:\n",
            "  Got post: sunt aut facere repellat provident occaecati excep...\n",
            "\n",
            "Invalid URL (404):\n",
            "HTTP Error: 404\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "\n",
        "def fetch_with_error_handling(url):\n",
        "    \"\"\"Fetch URL with proper error handling.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()  # Raises exception for 4xx/5xx\n",
        "        return response.json()\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"Timeout: Request took too long\")\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"HTTP Error: {e.response.status_code}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request failed: {e}\")\n",
        "    return None\n",
        "\n",
        "# Test with valid URL\n",
        "print(\"Valid URL:\")\n",
        "data = fetch_with_error_handling(\"https://jsonplaceholder.typicode.com/posts/1\")\n",
        "if data:\n",
        "    print(f\"  Got post: {data['title'][:50]}...\")\n",
        "\n",
        "# Test with invalid URL (404)\n",
        "print(\"\\nInvalid URL (404):\")\n",
        "fetch_with_error_handling(\"https://jsonplaceholder.typicode.com/posts/99999\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiY3EKnKxhcF"
      },
      "source": [
        "### Question 3.9: Robust Fetcher Function\n",
        "\n",
        "Write a function `safe_fetch(url, max_retries=3)` that:\n",
        "\n",
        "1. Attempts to fetch the URL\n",
        "2. If it fails with a 5xx error, retries up to `max_retries` times\n",
        "3. Waits 1 second between retries\n",
        "4. Returns the JSON data if successful, None otherwise\n",
        "\n",
        "Test it with `https://httpbin.org/status/500` (always returns 500) and `https://jsonplaceholder.typicode.com/posts/1` (always works)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "fuV7CYFpxhcF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing with working URL:\n",
            "Result: {'userId': 1, 'id': 1, 'title': 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit', 'body': 'quia et suscipit\\nsuscipit recusandae consequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto'}\n",
            "\n",
            "Testing with failing URL (500):\n",
            "Trying my ass off.....\n",
            "Filed after 1 tries\n",
            "Filed after 2 tries\n",
            "Filed after 3 tries\n",
            "Result: Fuck I can't do this anymore ðŸ˜­ðŸ˜­\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "import time\n",
        "\n",
        "def safe_fetch(url, max_retries=3):\n",
        "    \"\"\"Fetch URL with retry logic for server errors.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()  # Raises exception for 4xx/5xx\n",
        "        return response.json()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        if (500<=e.response.status_code<600):\n",
        "            print(f'Trying my ass off.....')\n",
        "            for i in range(max_retries):\n",
        "                try:\n",
        "                    response = requests.get(url, timeout=10)\n",
        "                    response.raise_for_status()  # Raises exception for 4xx/5xx\n",
        "                    return response.json()\n",
        "                except requests.exceptions.RequestException as e:\n",
        "                    if (500<=e.response.status_code<600):\n",
        "                        print(f'Filed after {i+1} tries')\n",
        "            \n",
        "    return \"Fuck I can't do this anymore ðŸ˜­ðŸ˜­\"\n",
        "# Test your function\n",
        "print(\"Testing with working URL:\")\n",
        "result = safe_fetch(\"https://jsonplaceholder.typicode.com/posts/1\")\n",
        "print(f\"Result: {result}\")\n",
        "\n",
        "print(\"\\nTesting with failing URL (500):\")\n",
        "result = safe_fetch(\"https://httpbin.org/status/500\")\n",
        "print(f\"Result: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHJfser-xhcF"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 4: The OMDb Movie API\n",
        "\n",
        "Now let's work with the OMDb API - our main data source for the Netflix project.\n",
        "\n",
        "**Note**: You need an API key from https://www.omdbapi.com/apikey.aspx (free tier available).\n",
        "\n",
        "For this lab, we'll use a demo key that has limited functionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uJkFzadFxhcF"
      },
      "outputs": [],
      "source": [
        "# Set your API key here\n",
        "# Get a free key from: https://www.omdbapi.com/apikey.aspx\n",
        "OMDB_API_KEY = \"1baeaa9\" # Replace with your actual key\n",
        "\n",
        "# For demo purposes, you can try with key \"demo\" but it's very limited\n",
        "# OMDB_API_KEY = \"demo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RpuA7EzxhcF"
      },
      "source": [
        "### Question 4.1 (Solved): Fetch a Single Movie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IbmFMp-3xhcF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Inception\n",
            "Year: 2010\n",
            "Director: Christopher Nolan\n",
            "IMDB Rating: 8.8\n",
            "Genre: Action, Adventure, Sci-Fi\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'Title': 'Inception',\n",
              " 'Year': '2010',\n",
              " 'Rated': 'PG-13',\n",
              " 'Released': '16 Jul 2010',\n",
              " 'Runtime': '148 min',\n",
              " 'Genre': 'Action, Adventure, Sci-Fi',\n",
              " 'Director': 'Christopher Nolan',\n",
              " 'Writer': 'Christopher Nolan',\n",
              " 'Actors': 'Leonardo DiCaprio, Joseph Gordon-Levitt, Elliot Page',\n",
              " 'Plot': 'A thief who steals corporate secrets through the use of dream-sharing technology is given the inverse task of planting an idea into the mind of a CEO, but his tragic past may doom the project and his team to disaster.',\n",
              " 'Language': 'English, Japanese, French',\n",
              " 'Country': 'United States, United Kingdom',\n",
              " 'Awards': 'Won 4 Oscars. 159 wins & 220 nominations total',\n",
              " 'Poster': 'https://m.media-amazon.com/images/M/MV5BMjAxMzY3NjcxNF5BMl5BanBnXkFtZTcwNTI5OTM0Mw@@._V1_SX300.jpg',\n",
              " 'Ratings': [{'Source': 'Internet Movie Database', 'Value': '8.8/10'},\n",
              "  {'Source': 'Rotten Tomatoes', 'Value': '87%'},\n",
              "  {'Source': 'Metacritic', 'Value': '74/100'}],\n",
              " 'Metascore': '74',\n",
              " 'imdbRating': '8.8',\n",
              " 'imdbVotes': '2,767,518',\n",
              " 'imdbID': 'tt1375666',\n",
              " 'Type': 'movie',\n",
              " 'DVD': 'N/A',\n",
              " 'BoxOffice': '$292,587,330',\n",
              " 'Production': 'N/A',\n",
              " 'Website': 'N/A',\n",
              " 'Response': 'True'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "\n",
        "def fetch_movie(title, year=None, api_key=OMDB_API_KEY):\n",
        "    \"\"\"Fetch movie data from OMDb API.\"\"\"\n",
        "    params = {\n",
        "        \"apikey\": api_key,\n",
        "        \"t\": title,  # Search by title\n",
        "        \"type\": \"movie\"\n",
        "    }\n",
        "    if year:\n",
        "        params[\"y\"] = year\n",
        "\n",
        "    response = requests.get(\"https://www.omdbapi.com/\", params=params)\n",
        "\n",
        "    if response.ok:\n",
        "        data = response.json()\n",
        "        if data.get(\"Response\") == \"True\":\n",
        "            return data\n",
        "        else:\n",
        "            print(f\"Movie not found: {data.get('Error')}\")\n",
        "    return None\n",
        "\n",
        "# Fetch Inception\n",
        "movie = fetch_movie(\"Inception\", 2010)\n",
        "if movie:\n",
        "    print(f\"Title: {movie['Title']}\")\n",
        "    print(f\"Year: {movie['Year']}\")\n",
        "    print(f\"Director: {movie['Director']}\")\n",
        "    print(f\"IMDB Rating: {movie['imdbRating']}\")\n",
        "    print(f\"Genre: {movie['Genre']}\")\n",
        "movie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kqn8N1dxhcF"
      },
      "source": [
        "### Question 4.2: Explore the Response\n",
        "\n",
        "Fetch data for \"The Dark Knight\" and print ALL available fields in the response.\n",
        "\n",
        "Which fields might be useful for predicting movie success?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "JvjP_v5WxhcF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Title': 'The Dark Knight',\n",
              " 'Year': '2008',\n",
              " 'Rated': 'PG-13',\n",
              " 'Released': '18 Jul 2008',\n",
              " 'Runtime': '152 min',\n",
              " 'Genre': 'Action, Crime, Drama',\n",
              " 'Director': 'Christopher Nolan',\n",
              " 'Writer': 'Jonathan Nolan, Christopher Nolan, David S. Goyer',\n",
              " 'Actors': 'Christian Bale, Heath Ledger, Aaron Eckhart',\n",
              " 'Plot': 'When a menace known as the Joker wreaks havoc and chaos on the people of Gotham, Batman, James Gordon and Harvey Dent must work together to put an end to the madness.',\n",
              " 'Language': 'English, Mandarin',\n",
              " 'Country': 'United States, United Kingdom',\n",
              " 'Awards': 'Won 2 Oscars. 163 wins & 165 nominations total',\n",
              " 'Poster': 'https://m.media-amazon.com/images/M/MV5BMTMxNTMwODM0NF5BMl5BanBnXkFtZTcwODAyMTk2Mw@@._V1_SX300.jpg',\n",
              " 'Ratings': [{'Source': 'Internet Movie Database', 'Value': '9.1/10'},\n",
              "  {'Source': 'Rotten Tomatoes', 'Value': '94%'},\n",
              "  {'Source': 'Metacritic', 'Value': '85/100'}],\n",
              " 'Metascore': '85',\n",
              " 'imdbRating': '9.1',\n",
              " 'imdbVotes': '3,115,102',\n",
              " 'imdbID': 'tt0468569',\n",
              " 'Type': 'movie',\n",
              " 'DVD': 'N/A',\n",
              " 'BoxOffice': '$534,987,076',\n",
              " 'Production': 'N/A',\n",
              " 'Website': 'N/A',\n",
              " 'Response': 'True'}"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "dark_knight = fetch_movie(\"The Dark Knight\")\n",
        "dark_knight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAlPEzP9xhcF"
      },
      "source": [
        "### Question 4.3: Fetch Multiple Movies\n",
        "\n",
        "Create a function `fetch_movies(titles)` that:\n",
        "1. Takes a list of movie titles\n",
        "2. Fetches data for each movie\n",
        "3. Returns a list of movie dictionaries (only successful fetches)\n",
        "4. Adds a 0.5 second delay between requests (to respect rate limits)\n",
        "\n",
        "Test it with: `[\"Inception\", \"The Matrix\", \"Interstellar\", \"NonExistentMovie123\"]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "qB40-ZL_xhcF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movie not found: Movie not found!\n",
            "Successfully fetched 3 out of 4 movies\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "def fetch_movies(titles, api_key = OMDB_API_KEY):\n",
        "    \"\"\"Fetch multiple movies from OMDb API.\"\"\"\n",
        "    success_movie_fetch = []\n",
        "    for title in titles:\n",
        "        params = {\n",
        "            \"apikey\": api_key,\n",
        "            \"t\": title,  # Search by title\n",
        "            \"type\": \"movie\"\n",
        "        }\n",
        "\n",
        "        response = requests.get(\"https://www.omdbapi.com/\", params=params)\n",
        "\n",
        "        if response.ok:\n",
        "            data = response.json()\n",
        "            if data.get(\"Response\") == \"True\":\n",
        "                success_movie_fetch.append(data)\n",
        "            else:\n",
        "                print(f\"Movie not found: {data.get('Error')}\")\n",
        "        time.sleep(0.5)\n",
        "    return success_movie_fetch\n",
        "\n",
        "# Test\n",
        "test_titles = [\"Inception\", \"The Matrix\", \"Interstellar\", \"NonExistentMovie123\"]\n",
        "movies = fetch_movies(test_titles)\n",
        "print(f\"Successfully fetched {len(movies)} out of {len(test_titles)} movies\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'Title': 'Inception',\n",
              "  'Year': '2010',\n",
              "  'Rated': 'PG-13',\n",
              "  'Released': '16 Jul 2010',\n",
              "  'Runtime': '148 min',\n",
              "  'Genre': 'Action, Adventure, Sci-Fi',\n",
              "  'Director': 'Christopher Nolan',\n",
              "  'Writer': 'Christopher Nolan',\n",
              "  'Actors': 'Leonardo DiCaprio, Joseph Gordon-Levitt, Elliot Page',\n",
              "  'Plot': 'A thief who steals corporate secrets through the use of dream-sharing technology is given the inverse task of planting an idea into the mind of a CEO, but his tragic past may doom the project and his team to disaster.',\n",
              "  'Language': 'English, Japanese, French',\n",
              "  'Country': 'United States, United Kingdom',\n",
              "  'Awards': 'Won 4 Oscars. 159 wins & 220 nominations total',\n",
              "  'Poster': 'https://m.media-amazon.com/images/M/MV5BMjAxMzY3NjcxNF5BMl5BanBnXkFtZTcwNTI5OTM0Mw@@._V1_SX300.jpg',\n",
              "  'Ratings': [{'Source': 'Internet Movie Database', 'Value': '8.8/10'},\n",
              "   {'Source': 'Rotten Tomatoes', 'Value': '87%'},\n",
              "   {'Source': 'Metacritic', 'Value': '74/100'}],\n",
              "  'Metascore': '74',\n",
              "  'imdbRating': '8.8',\n",
              "  'imdbVotes': '2,767,518',\n",
              "  'imdbID': 'tt1375666',\n",
              "  'Type': 'movie',\n",
              "  'DVD': 'N/A',\n",
              "  'BoxOffice': '$292,587,330',\n",
              "  'Production': 'N/A',\n",
              "  'Website': 'N/A',\n",
              "  'Response': 'True'},\n",
              " {'Title': 'The Matrix',\n",
              "  'Year': '1999',\n",
              "  'Rated': 'R',\n",
              "  'Released': '31 Mar 1999',\n",
              "  'Runtime': '136 min',\n",
              "  'Genre': 'Action, Sci-Fi',\n",
              "  'Director': 'Lana Wachowski, Lilly Wachowski',\n",
              "  'Writer': 'Lilly Wachowski, Lana Wachowski',\n",
              "  'Actors': 'Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss',\n",
              "  'Plot': 'When a beautiful stranger leads computer hacker Neo to a forbidding underworld, he discovers the shocking truth--the life he knows is the elaborate deception of an evil cyber-intelligence.',\n",
              "  'Language': 'English',\n",
              "  'Country': 'United States, Australia',\n",
              "  'Awards': 'Won 4 Oscars. 42 wins & 52 nominations total',\n",
              "  'Poster': 'https://m.media-amazon.com/images/M/MV5BN2NmN2VhMTQtMDNiOS00NDlhLTliMjgtODE2ZTY0ODQyNDRhXkEyXkFqcGc@._V1_SX300.jpg',\n",
              "  'Ratings': [{'Source': 'Internet Movie Database', 'Value': '8.7/10'},\n",
              "   {'Source': 'Rotten Tomatoes', 'Value': '83%'},\n",
              "   {'Source': 'Metacritic', 'Value': '73/100'}],\n",
              "  'Metascore': '73',\n",
              "  'imdbRating': '8.7',\n",
              "  'imdbVotes': '2,217,731',\n",
              "  'imdbID': 'tt0133093',\n",
              "  'Type': 'movie',\n",
              "  'DVD': 'N/A',\n",
              "  'BoxOffice': '$177,559,005',\n",
              "  'Production': 'N/A',\n",
              "  'Website': 'N/A',\n",
              "  'Response': 'True'},\n",
              " {'Title': 'Interstellar',\n",
              "  'Year': '2014',\n",
              "  'Rated': 'PG-13',\n",
              "  'Released': '07 Nov 2014',\n",
              "  'Runtime': '169 min',\n",
              "  'Genre': 'Adventure, Drama, Sci-Fi',\n",
              "  'Director': 'Christopher Nolan',\n",
              "  'Writer': 'Jonathan Nolan, Christopher Nolan',\n",
              "  'Actors': 'Matthew McConaughey, Anne Hathaway, Jessica Chastain',\n",
              "  'Plot': 'When Earth becomes uninhabitable in the future, a farmer and ex-NASA pilot, Joseph Cooper, is tasked to pilot a spacecraft, along with a team of researchers, to find a new planet for humans.',\n",
              "  'Language': 'English',\n",
              "  'Country': 'United States, United Kingdom, Canada',\n",
              "  'Awards': 'Won 1 Oscar. 45 wins & 148 nominations total',\n",
              "  'Poster': 'https://m.media-amazon.com/images/M/MV5BYzdjMDAxZGItMjI2My00ODA1LTlkNzItOWFjMDU5ZDJlYWY3XkEyXkFqcGc@._V1_SX300.jpg',\n",
              "  'Ratings': [{'Source': 'Internet Movie Database', 'Value': '8.7/10'},\n",
              "   {'Source': 'Rotten Tomatoes', 'Value': '73%'},\n",
              "   {'Source': 'Metacritic', 'Value': '74/100'}],\n",
              "  'Metascore': '74',\n",
              "  'imdbRating': '8.7',\n",
              "  'imdbVotes': '2,454,660',\n",
              "  'imdbID': 'tt0816692',\n",
              "  'Type': 'movie',\n",
              "  'DVD': 'N/A',\n",
              "  'BoxOffice': '$203,227,580',\n",
              "  'Production': 'N/A',\n",
              "  'Website': 'N/A',\n",
              "  'Response': 'True'}]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br37jdR7xhcF"
      },
      "source": [
        "### Question 4.4: Create a Movie DataFrame\n",
        "\n",
        "Using the movies you fetched, create a pandas DataFrame with these columns:\n",
        "- title\n",
        "- year (as integer)\n",
        "- genre\n",
        "- director\n",
        "- imdb_rating (as float)\n",
        "- imdb_votes (as integer, remove commas)\n",
        "- runtime_minutes (as integer, extract from \"148 min\")\n",
        "- box_office (keep as string for now)\n",
        "\n",
        "**Hint**: You'll need to clean the data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "qxtrIrSpxhcF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Director</th>\n",
              "      <th>imdbRating</th>\n",
              "      <th>Genre</th>\n",
              "      <th>imdbVotes</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>BoxOffice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Inception</td>\n",
              "      <td>2010</td>\n",
              "      <td>Christopher Nolan</td>\n",
              "      <td>8.8</td>\n",
              "      <td>Action, Adventure, Sci-Fi</td>\n",
              "      <td>2767518</td>\n",
              "      <td>148</td>\n",
              "      <td>$292,587,330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Matrix</td>\n",
              "      <td>1999</td>\n",
              "      <td>Lana Wachowski, Lilly Wachowski</td>\n",
              "      <td>8.7</td>\n",
              "      <td>Action, Sci-Fi</td>\n",
              "      <td>2217731</td>\n",
              "      <td>136</td>\n",
              "      <td>$177,559,005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Interstellar</td>\n",
              "      <td>2014</td>\n",
              "      <td>Christopher Nolan</td>\n",
              "      <td>8.7</td>\n",
              "      <td>Adventure, Drama, Sci-Fi</td>\n",
              "      <td>2454660</td>\n",
              "      <td>169</td>\n",
              "      <td>$203,227,580</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Title  Year                         Director  imdbRating  \\\n",
              "0     Inception  2010                Christopher Nolan         8.8   \n",
              "1    The Matrix  1999  Lana Wachowski, Lilly Wachowski         8.7   \n",
              "2  Interstellar  2014                Christopher Nolan         8.7   \n",
              "\n",
              "                       Genre  imdbVotes  Runtime     BoxOffice  \n",
              "0  Action, Adventure, Sci-Fi    2767518      148  $292,587,330  \n",
              "1             Action, Sci-Fi    2217731      136  $177,559,005  \n",
              "2   Adventure, Drama, Sci-Fi    2454660      169  $203,227,580  "
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "df = pd.DataFrame(movies)\n",
        "df_required = df[['Title', 'Year', 'Director', 'imdbRating', 'Genre', 'imdbVotes', 'Runtime', 'BoxOffice']]\n",
        "df_required['Year'] = pd.to_numeric(df_required['Year'], errors='coerce').astype(int)\n",
        "df_required['imdbRating'] = pd.to_numeric(df_required['imdbRating'], errors='coerce').astype(float)\n",
        "df_required['imdbVotes'] = df_required['imdbVotes'].str.replace(',', '').astype(int)\n",
        "df_required['Runtime'] = df_required['Runtime'].str.replace(' min', '').astype(int)\n",
        "df_required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU2Xs7mRxhcF"
      },
      "source": [
        "### Question 4.5: Search Movies by Title\n",
        "\n",
        "OMDb also has a search endpoint that returns multiple results.\n",
        "\n",
        "Use the `s` parameter instead of `t` to search for movies containing \"Star Wars\".\n",
        "\n",
        "API endpoint: `https://www.omdbapi.com/?apikey=YOUR_KEY&s=Star Wars&type=movie`\n",
        "\n",
        "Print the title and year of each result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "jUi_smaxxhcF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The title of the movie: Star Wars: Episode IV - A New Hope, and the year is: 1977\n",
            "The title of the movie: Star Wars: Episode V - The Empire Strikes Back, and the year is: 1980\n",
            "The title of the movie: Star Wars: Episode VI - Return of the Jedi, and the year is: 1983\n",
            "The title of the movie: Star Wars: Episode VII - The Force Awakens, and the year is: 2015\n",
            "The title of the movie: Star Wars: Episode I - The Phantom Menace, and the year is: 1999\n",
            "The title of the movie: Star Wars: Episode III - Revenge of the Sith, and the year is: 2005\n",
            "The title of the movie: Star Wars: Episode II - Attack of the Clones, and the year is: 2002\n",
            "The title of the movie: Rogue One: A Star Wars Story, and the year is: 2016\n",
            "The title of the movie: Star Wars: Episode VIII - The Last Jedi, and the year is: 2017\n",
            "The title of the movie: Star Wars: Episode IX - The Rise of Skywalker, and the year is: 2019\n"
          ]
        }
      ],
      "source": [
        "response = requests.get(\"https://www.omdbapi.com/?apikey=1baeaa9&s=Star Wars&type=movie\")\n",
        "for search in response.json()['Search']:\n",
        "    print(f\"The title of the movie: {search['Title']}, and the year is: {search['Year']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Search': [{'Title': 'Star Wars: Episode IV - A New Hope',\n",
              "   'Year': '1977',\n",
              "   'imdbID': 'tt0076759',\n",
              "   'Type': 'movie',\n",
              "   'Poster': 'https://m.media-amazon.com/images/M/MV5BOGUwMDk0Y2MtNjBlNi00NmRiLTk2MWYtMGMyMDlhYmI4ZDBjXkEyXkFqcGc@._V1_SX300.jpg'},\n",
              "  {'Title': 'Star Wars: Episode V - The Empire Strikes Back',\n",
              "   'Year': '1980',\n",
              "   'imdbID': 'tt0080684',\n",
              "   'Type': 'movie',\n",
              "   'Poster': 'https://m.media-amazon.com/images/M/MV5BMTkxNGFlNDktZmJkNC00MDdhLTg0MTEtZjZiYWI3MGE5NWIwXkEyXkFqcGc@._V1_SX300.jpg'},\n",
              "  {'Title': 'Star Wars: Episode VI - Return of the Jedi',\n",
              "   'Year': '1983',\n",
              "   'imdbID': 'tt0086190',\n",
              "   'Type': 'movie',\n",
              "   'Poster': 'https://m.media-amazon.com/images/M/MV5BNWEwOTI0MmUtMGNmNy00ODViLTlkZDQtZTg1YmQ3MDgyNTUzXkEyXkFqcGc@._V1_SX300.jpg'},\n",
              "  {'Title': 'Star Wars: Episode VII - The Force Awakens',\n",
              "   'Year': '2015',\n",
              "   'imdbID': 'tt2488496',\n",
              "   'Type': 'movie',\n",
              "   'Poster': 'https://m.media-amazon.com/images/M/MV5BOTAzODEzNDAzMl5BMl5BanBnXkFtZTgwMDU1MTgzNzE@._V1_SX300.jpg'},\n",
              "  {'Title': 'Star Wars: Episode I - The Phantom Menace',\n",
              "   'Year': '1999',\n",
              "   'imdbID': 'tt0120915',\n",
              "   'Type': 'movie',\n",
              "   'Poster': 'https://m.media-amazon.com/images/M/MV5BODVhNGIxOGItYWNlMi00YTA0LWI3NTctZmQxZGUwZDEyZWI4XkEyXkFqcGc@._V1_SX300.jpg'},\n",
              "  {'Title': 'Star Wars: Episode III - Revenge of the Sith',\n",
              "   'Year': '2005',\n",
              "   'imdbID': 'tt0121766',\n",
              "   'Type': 'movie',\n",
              "   'Poster': 'https://m.media-amazon.com/images/M/MV5BNTc4MTc3NTQ5OF5BMl5BanBnXkFtZTcwOTg0NjI4NA@@._V1_SX300.jpg'},\n",
              "  {'Title': 'Star Wars: Episode II - Attack of the Clones',\n",
              "   'Year': '2002',\n",
              "   'imdbID': 'tt0121765',\n",
              "   'Type': 'movie',\n",
              "   'Poster': 'https://m.media-amazon.com/images/M/MV5BNTgxMjY2YzUtZmVmNC00YjAwLWJlODMtNDBhNzllNzIzMjgxXkEyXkFqcGc@._V1_SX300.jpg'},\n",
              "  {'Title': 'Rogue One: A Star Wars Story',\n",
              "   'Year': '2016',\n",
              "   'imdbID': 'tt3748528',\n",
              "   'Type': 'movie',\n",
              "   'Poster': 'https://m.media-amazon.com/images/M/MV5BMjEwMzMxODIzOV5BMl5BanBnXkFtZTgwNzg3OTAzMDI@._V1_SX300.jpg'},\n",
              "  {'Title': 'Star Wars: Episode VIII - The Last Jedi',\n",
              "   'Year': '2017',\n",
              "   'imdbID': 'tt2527336',\n",
              "   'Type': 'movie',\n",
              "   'Poster': 'https://m.media-amazon.com/images/M/MV5BMjQ1MzcxNjg4N15BMl5BanBnXkFtZTgwNzgwMjY4MzI@._V1_SX300.jpg'},\n",
              "  {'Title': 'Star Wars: Episode IX - The Rise of Skywalker',\n",
              "   'Year': '2019',\n",
              "   'imdbID': 'tt2527338',\n",
              "   'Type': 'movie',\n",
              "   'Poster': 'https://m.media-amazon.com/images/M/MV5BODg5ZTNmMTUtYThlNy00NjljLWE0MGUtYmQ1NDg4NWU5MjQ1XkEyXkFqcGc@._V1_SX300.jpg'}],\n",
              " 'totalResults': '693',\n",
              " 'Response': 'True'}"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYG9BUvPxhcG"
      },
      "source": [
        "### Question 4.6: Handle Pagination\n",
        "\n",
        "The OMDb search API returns 10 results per page and includes a `totalResults` field.\n",
        "\n",
        "Write a function `search_all_movies(query)` that:\n",
        "1. Searches for movies matching the query\n",
        "2. Fetches ALL pages of results (use the `page` parameter)\n",
        "3. Returns a list of all movies found\n",
        "\n",
        "**Hint**: `totalResults` tells you how many movies exist. Divide by 10 to get the number of pages.\n",
        "\n",
        "Test with a query that has many results like \"Batman\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "zkPcXdFNxhcG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 514 Batman movies\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "def search_all_movies(query, api_key=OMDB_API_KEY):\n",
        "    \"\"\"Search OMDb and return ALL matching movies across all pages.\"\"\"\n",
        "    all_batman_movies = []\n",
        "    params = {\n",
        "        \"apikey\": api_key,\n",
        "        \"s\": query,  # Search by title\n",
        "        \"type\": \"movie\",\n",
        "    }\n",
        "    response = requests.get(\"https://www.omdbapi.com/\", params=params)\n",
        "    for i in range(int(response.json()['totalResults'])//10+1):\n",
        "        params = {\n",
        "            \"apikey\": api_key,\n",
        "            \"s\": query,  # Search by title\n",
        "            \"type\": \"movie\",\n",
        "            \"page\": i+1\n",
        "        }\n",
        "        response = requests.get(\"https://www.omdbapi.com/\", params=params)\n",
        "        for search in response.json()['Search']:\n",
        "            all_batman_movies.append(search['Title'])\n",
        "\n",
        "    return all_batman_movies\n",
        "# Test\n",
        "all_batman = search_all_movies(\"Batman\")\n",
        "print(f\"Found {len(all_batman)} Batman movies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To7cgqPGxhcG"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 5: Web Scraping with BeautifulSoup\n",
        "\n",
        "When APIs don't exist or don't have what we need, we scrape.\n",
        "\n",
        "## 5.1 HTML Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEUiA8_txhcG"
      },
      "source": [
        "### Question 5.1 (Solved): Parse HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QHoa6-n0xhcG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 movies\n",
            "\n",
            "Inception (2010) - Rating: 8.8 - Link: /movies/inception\n",
            "The Matrix (1999) - Rating: 8.7 - Link: /movies/matrix\n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html = \"\"\"\n",
        "<html>\n",
        "<body>\n",
        "    <div class=\"movie\" id=\"movie-1\">\n",
        "        <h2 class=\"title\">Inception</h2>\n",
        "        <span class=\"year\">2010</span>\n",
        "        <span class=\"rating\">8.8</span>\n",
        "        <a href=\"/movies/inception\">More Info</a>\n",
        "    </div>\n",
        "    <div class=\"movie\" id=\"movie-2\">\n",
        "        <h2 class=\"title\">The Matrix</h2>\n",
        "        <span class=\"year\">1999</span>\n",
        "        <span class=\"rating\">8.7</span>\n",
        "        <a href=\"/movies/matrix\">More Info</a>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# Find all movie divs\n",
        "movies = soup.find_all('div', class_='movie')\n",
        "print(f\"Found {len(movies)} movies\\n\")\n",
        "\n",
        "# Extract data from each\n",
        "for movie in movies:\n",
        "    title = movie.find('h2', class_='title').text\n",
        "    year = movie.find('span', class_='year').text\n",
        "    rating = movie.find('span', class_='rating').text\n",
        "    link = movie.find('a')['href']\n",
        "\n",
        "    print(f\"{title} ({year}) - Rating: {rating} - Link: {link}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpMc2qdUxhcG"
      },
      "source": [
        "### Question 5.2: CSS Selectors\n",
        "\n",
        "Rewrite the above extraction using CSS selectors (`.select()` and `.select_one()`) instead of `.find()` and `.find_all()`.\n",
        "\n",
        "**Hint**:\n",
        "- `.movie` selects elements with class \"movie\"\n",
        "- `.movie .title` selects elements with class \"title\" inside class \"movie\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "kZN86W9kxhcG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 movies\n",
            "\n",
            "Inception (2010) - Rating: 8.8 - Link: /movies/inception\n",
            "The Matrix (1999) - Rating: 8.7 - Link: /movies/matrix\n",
            "Found 2 titles using CSS selectors:\n",
            "\n",
            "Inception (2010) - Rating: 8.8 - Link: /movies/inception\n",
            "The Matrix (1999) - Rating: 8.7 - Link: /movies/matrix\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Use the same 'soup' from above\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# Find all movie divs\n",
        "movies = soup.find_all('div', class_='movie')\n",
        "print(f\"Found {len(movies)} movies\\n\")\n",
        "\n",
        "# Extract data from each\n",
        "for movie in movies:\n",
        "    title = movie.find('h2', class_='title').text\n",
        "    year = movie.find('span', class_='year').text\n",
        "    rating = movie.find('span', class_='rating').text\n",
        "    link = movie.find('a')['href']\n",
        "\n",
        "    print(f\"{title} ({year}) - Rating: {rating} - Link: {link}\")\n",
        "\n",
        "# Extract using CSS selectors\n",
        "keywords = soup.select('div.movie')\n",
        "print(f'Found {len(keywords)} titles using CSS selectors:\\n')\n",
        "for keyword in keywords:\n",
        "    title = keyword.find('h2', class_='title').text\n",
        "    year = keyword.find('span', class_='year').text\n",
        "    rating = keyword.find('span', class_='rating').text\n",
        "    link = keyword.find('a')['href']\n",
        "    print(f\"{title} ({year}) - Rating: {rating} - Link: {link}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These two lines of code essentially do the same search over movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([<div class=\"movie\" id=\"movie-1\">\n",
              "  <h2 class=\"title\">Inception</h2>\n",
              "  <span class=\"year\">2010</span>\n",
              "  <span class=\"rating\">8.8</span>\n",
              "  <a href=\"/movies/inception\">More Info</a>\n",
              "  </div>,\n",
              "  <div class=\"movie\" id=\"movie-2\">\n",
              "  <h2 class=\"title\">The Matrix</h2>\n",
              "  <span class=\"year\">1999</span>\n",
              "  <span class=\"rating\">8.7</span>\n",
              "  <a href=\"/movies/matrix\">More Info</a>\n",
              "  </div>],\n",
              " [<div class=\"movie\" id=\"movie-1\">\n",
              "  <h2 class=\"title\">Inception</h2>\n",
              "  <span class=\"year\">2010</span>\n",
              "  <span class=\"rating\">8.8</span>\n",
              "  <a href=\"/movies/inception\">More Info</a>\n",
              "  </div>,\n",
              "  <div class=\"movie\" id=\"movie-2\">\n",
              "  <h2 class=\"title\">The Matrix</h2>\n",
              "  <span class=\"year\">1999</span>\n",
              "  <span class=\"rating\">8.7</span>\n",
              "  <a href=\"/movies/matrix\">More Info</a>\n",
              "  </div>])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "key = soup.select('div.movie')\n",
        "mov = soup.find_all('div', class_='movie')\n",
        "key, mov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm0QHkB0xhcG"
      },
      "source": [
        "### Question 5.3: Scrape a Real Website\n",
        "\n",
        "Let's scrape the example website `http://quotes.toscrape.com/` which is designed for scraping practice.\n",
        "\n",
        "Extract all quotes from the first page, including:\n",
        "- The quote text\n",
        "- The author name\n",
        "- The tags\n",
        "\n",
        "Return the results as a list of dictionaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU3xC_h7xhcG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n",
            "Found 10 quotes:\n",
            "\n",
            "â€œThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.â€\n",
            "â€œIt is our choices, Harry, that show what we truly are, far more than our abilities.â€\n",
            "â€œThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.â€\n",
            "â€œThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.â€\n",
            "â€œImperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.â€\n",
            "â€œTry not to become a man of success. Rather become a man of value.â€\n",
            "â€œIt is better to be hated for what you are than to be loved for what you are not.â€\n",
            "â€œI have not failed. I've just found 10,000 ways that won't work.â€\n",
            "â€œA woman is like a tea bag; you never know how strong it is until it's in hot water.â€\n",
            "â€œA day without sunshine is like, you know, night.â€\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Fetch the page\n",
        "url = \"http://quotes.toscrape.com/\"\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status() # Raise an exception for bad status codes\n",
        "    print(response.status_code)\n",
        "\n",
        "    html_content = response.text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Extract quotes\n",
        "quotes = soup.select('div.quote > span.text')\n",
        "\n",
        "# Print results\n",
        "print(f'Found {len(quotes)} quotes:\\n')\n",
        "for quote in quotes:\n",
        "    print(quote.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbn682HOxhcG"
      },
      "source": [
        "### Question 5.4: Handle Pagination in Scraping\n",
        "\n",
        "The quotes website has multiple pages. Scrape the first 3 pages and collect all quotes.\n",
        "\n",
        "Pages follow the pattern:\n",
        "- Page 1: `http://quotes.toscrape.com/page/1/`\n",
        "- Page 2: `http://quotes.toscrape.com/page/2/`\n",
        "- etc.\n",
        "\n",
        "**Remember**: Add a delay between requests to be polite!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "vLGhBfY0xhcG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200\n",
            "Found 10 quotes in page 1:\n",
            "\n",
            "â€œThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.â€\n",
            "â€œIt is our choices, Harry, that show what we truly are, far more than our abilities.â€\n",
            "â€œThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.â€\n",
            "â€œThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.â€\n",
            "â€œImperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.â€\n",
            "â€œTry not to become a man of success. Rather become a man of value.â€\n",
            "â€œIt is better to be hated for what you are than to be loved for what you are not.â€\n",
            "â€œI have not failed. I've just found 10,000 ways that won't work.â€\n",
            "â€œA woman is like a tea bag; you never know how strong it is until it's in hot water.â€\n",
            "â€œA day without sunshine is like, you know, night.â€\n",
            "200\n",
            "Found 10 quotes in page 2:\n",
            "\n",
            "â€œThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.â€\n",
            "â€œIt is our choices, Harry, that show what we truly are, far more than our abilities.â€\n",
            "â€œThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.â€\n",
            "â€œThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.â€\n",
            "â€œImperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.â€\n",
            "â€œTry not to become a man of success. Rather become a man of value.â€\n",
            "â€œIt is better to be hated for what you are than to be loved for what you are not.â€\n",
            "â€œI have not failed. I've just found 10,000 ways that won't work.â€\n",
            "â€œA woman is like a tea bag; you never know how strong it is until it's in hot water.â€\n",
            "â€œA day without sunshine is like, you know, night.â€\n",
            "200\n",
            "Found 10 quotes in page 3:\n",
            "\n",
            "â€œThe world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.â€\n",
            "â€œIt is our choices, Harry, that show what we truly are, far more than our abilities.â€\n",
            "â€œThere are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.â€\n",
            "â€œThe person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.â€\n",
            "â€œImperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.â€\n",
            "â€œTry not to become a man of success. Rather become a man of value.â€\n",
            "â€œIt is better to be hated for what you are than to be loved for what you are not.â€\n",
            "â€œI have not failed. I've just found 10,000 ways that won't work.â€\n",
            "â€œA woman is like a tea bag; you never know how strong it is until it's in hot water.â€\n",
            "â€œA day without sunshine is like, you know, night.â€\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "url = \"http://quotes.toscrape.com/\"\n",
        "for i in range(1, 4):\n",
        "    params = {'page': i}\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status() # Raise an exception for bad status codes\n",
        "        print(response.status_code)\n",
        "\n",
        "        html_content = response.text\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "        # Extract quotes\n",
        "        quotes = soup.select('div.quote > span.text')\n",
        "\n",
        "        # Print results\n",
        "        print(f'Found {len(quotes)} quotes in page {i}:\\n')\n",
        "        for quote in quotes:\n",
        "            print(quote.text)\n",
        "\n",
        "        time.sleep(1)  # Be polite and avoid overwhelming the server\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H31_5_SxhcG"
      },
      "source": [
        "### Question 5.5: Extract Table Data\n",
        "\n",
        "Scrape the table from `https://www.w3schools.com/html/html_tables.asp`.\n",
        "\n",
        "The table contains company data. Extract all rows and create a pandas DataFrame.\n",
        "\n",
        "**Hint**: Look for `<table>`, `<tr>` (table row), `<th>` (header), and `<td>` (data cell) elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T7W8Z4EsxhcG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Company Contact Country \n",
            "Alfreds Futterkiste Maria Anders Germany \n",
            "Centro comercial Moctezuma Francisco Chang Mexico \n",
            "Ernst Handel Roland Mendel Austria \n",
            "Island Trading Helen Bennett UK \n",
            "Laughing Bacchus Winecellars Yoshi Tannamuri Canada \n",
            "Magazzini Alimentari Riuniti Giovanni Rovelli Italy \n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Hint: pandas has a read_html() function that can do this automatically!\n",
        "# But try doing it manually first to understand the process.\n",
        "url = \"https://www.w3schools.com/html/html_tables.asp\"\n",
        "response = requests.get(url)\n",
        "\n",
        "html_content = response.text\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "table = soup.find('table')\n",
        "\n",
        "for tr in table.find_all('tr'):\n",
        "    for th in tr.find_all('th'):\n",
        "        print(th.text, end=\" \")\n",
        "    \n",
        "    for td in tr.find_all('td'):\n",
        "        print(td.text, end=' ')\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_78659/2525532223.py:1: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_html(str(response.text))[0]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Company</th>\n",
              "      <th>Contact</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alfreds Futterkiste</td>\n",
              "      <td>Maria Anders</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Centro comercial Moctezuma</td>\n",
              "      <td>Francisco Chang</td>\n",
              "      <td>Mexico</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ernst Handel</td>\n",
              "      <td>Roland Mendel</td>\n",
              "      <td>Austria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Island Trading</td>\n",
              "      <td>Helen Bennett</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Laughing Bacchus Winecellars</td>\n",
              "      <td>Yoshi Tannamuri</td>\n",
              "      <td>Canada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Magazzini Alimentari Riuniti</td>\n",
              "      <td>Giovanni Rovelli</td>\n",
              "      <td>Italy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Company           Contact  Country\n",
              "0           Alfreds Futterkiste      Maria Anders  Germany\n",
              "1    Centro comercial Moctezuma   Francisco Chang   Mexico\n",
              "2                  Ernst Handel     Roland Mendel  Austria\n",
              "3                Island Trading     Helen Bennett       UK\n",
              "4  Laughing Bacchus Winecellars   Yoshi Tannamuri   Canada\n",
              "5  Magazzini Alimentari Riuniti  Giovanni Rovelli    Italy"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_html(str(response.text))[0]\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jED1QI_VxhcH"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 6: Building the Movie Data Pipeline\n",
        "\n",
        "Now let's put everything together to build a complete data collection pipeline for our Netflix project.\n",
        "\n",
        "## 6.1 The Complete Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MwYiNAlxhcH"
      },
      "source": [
        "### Question 6.1 (Solved): Movie Data Collector Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fMNFFDK7xhcH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching 1/2: Inception\n",
            "Fetching 2/2: The Matrix\n",
            "        title  year                      genre  \\\n",
            "0   Inception  2010  Action, Adventure, Sci-Fi   \n",
            "1  The Matrix  1999             Action, Sci-Fi   \n",
            "\n",
            "                          director  \\\n",
            "0                Christopher Nolan   \n",
            "1  Lana Wachowski, Lilly Wachowski   \n",
            "\n",
            "                                              actors  imdb_rating  imdb_votes  \\\n",
            "0  Leonardo DiCaprio, Joseph Gordon-Levitt, Ellio...          8.8     2767518   \n",
            "1  Keanu Reeves, Laurence Fishburne, Carrie-Anne ...          8.7     2217731   \n",
            "\n",
            "   runtime    box_office    imdb_id  runtime_min  \n",
            "0  148 min  $292,587,330  tt1375666          148  \n",
            "1  136 min  $177,559,005  tt0133093          136  \n"
          ]
        }
      ],
      "source": [
        "# SOLVED EXAMPLE\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "class MovieDataCollector:\n",
        "    \"\"\"Collect movie data from OMDb API.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"http://www.omdbapi.com/\"\n",
        "        self.delay = 0.5  # Seconds between requests\n",
        "\n",
        "    def fetch_movie(self, title: str, year: Optional[int] = None) -> Optional[Dict]:\n",
        "        \"\"\"Fetch a single movie by title.\"\"\"\n",
        "        params = {\n",
        "            \"apikey\": self.api_key,\n",
        "            \"t\": title,\n",
        "            \"type\": \"movie\"\n",
        "        }\n",
        "        if year:\n",
        "            params[\"y\"] = year\n",
        "\n",
        "        try:\n",
        "            response = requests.get(self.base_url, params=params, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            data = response.json()\n",
        "\n",
        "            if data.get(\"Response\") == \"True\":\n",
        "                return data\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {title}: {e}\")\n",
        "\n",
        "        return None\n",
        "\n",
        "    def fetch_movies(self, titles: List[str]) -> List[Dict]:\n",
        "        \"\"\"Fetch multiple movies.\"\"\"\n",
        "        movies = []\n",
        "\n",
        "        for i, title in enumerate(titles):\n",
        "            print(f\"Fetching {i+1}/{len(titles)}: {title}\")\n",
        "            movie = self.fetch_movie(title)\n",
        "\n",
        "            if movie:\n",
        "                movies.append(movie)\n",
        "\n",
        "            time.sleep(self.delay)\n",
        "\n",
        "        return movies\n",
        "\n",
        "    def to_dataframe(self, movies: List[Dict]) -> pd.DataFrame:\n",
        "        \"\"\"Convert movie data to cleaned DataFrame.\"\"\"\n",
        "        if not movies:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Extract relevant fields\n",
        "        rows = []\n",
        "        for m in movies:\n",
        "            rows.append({\n",
        "                \"title\": m.get(\"Title\"),\n",
        "                \"year\": m.get(\"Year\"),\n",
        "                \"genre\": m.get(\"Genre\"),\n",
        "                \"director\": m.get(\"Director\"),\n",
        "                \"actors\": m.get(\"Actors\"),\n",
        "                \"imdb_rating\": m.get(\"imdbRating\"),\n",
        "                \"imdb_votes\": m.get(\"imdbVotes\"),\n",
        "                \"runtime\": m.get(\"Runtime\"),\n",
        "                \"box_office\": m.get(\"BoxOffice\"),\n",
        "                \"imdb_id\": m.get(\"imdbID\")\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(rows)\n",
        "\n",
        "        # Clean data types\n",
        "        df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
        "        df[\"imdb_rating\"] = pd.to_numeric(df[\"imdb_rating\"], errors=\"coerce\")\n",
        "        df[\"imdb_votes\"] = df[\"imdb_votes\"].str.replace(\",\", \"\").pipe(pd.to_numeric, errors=\"coerce\").astype(\"Int64\")\n",
        "        # Fix: str.extract returns a DataFrame, we need column 0 to get a Series\n",
        "        df[\"runtime_min\"] = df[\"runtime\"].str.extract(r\"(\\d+)\")[0].pipe(pd.to_numeric, errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "        return df\n",
        "\n",
        "# Usage example\n",
        "collector = MovieDataCollector(OMDB_API_KEY)\n",
        "movies = collector.fetch_movies([\"Inception\", \"The Matrix\"])\n",
        "df = collector.to_dataframe(movies)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ks8pos-xhcH"
      },
      "source": [
        "### Question 6.2: Add Search Functionality\n",
        "\n",
        "Extend the `MovieDataCollector` class to add a `search_movies(query, max_results=50)` method that:\n",
        "1. Searches for movies matching the query\n",
        "2. Handles pagination to get up to `max_results` movies\n",
        "3. For each search result, fetches the full movie details\n",
        "4. Returns the detailed movie data\n",
        "\n",
        "**Hint**: Search results only contain basic info (title, year, poster, imdbID). You need to use the imdbID to fetch full details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHzLJZ_mxhcH"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# Extend the MovieDataCollector class or add a method\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSzZM4-9xhcH"
      },
      "source": [
        "### Question 6.3: Build a Genre-Based Dataset\n",
        "\n",
        "Use your collector to build a dataset of popular movies from different genres:\n",
        "\n",
        "1. Search for 10 movies each for: \"action\", \"comedy\", \"drama\", \"horror\", \"sci-fi\"\n",
        "2. Combine all results into a single DataFrame\n",
        "3. Remove any duplicates (some movies might appear in multiple searches)\n",
        "4. Save to CSV\n",
        "\n",
        "**Note**: This might take a while due to rate limiting. Start with fewer movies for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTUfJ8xgxhcH"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rja3jG-_xhcH"
      },
      "source": [
        "### Question 6.4: Data Quality Analysis\n",
        "\n",
        "Using the dataset you created:\n",
        "\n",
        "1. How many movies have missing IMDB ratings?\n",
        "2. How many movies have missing box office data?\n",
        "3. What's the distribution of ratings? (min, max, mean, median)\n",
        "4. Which directors appear most frequently?\n",
        "5. What's the average runtime by genre?\n",
        "\n",
        "These quality checks will be important for Week 2 (Data Validation)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDvNsMojxhcH"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO1u8ITNxhcH"
      },
      "source": [
        "---\n",
        "\n",
        "# Part 7: Challenge Problems\n",
        "\n",
        "These are optional advanced exercises for those who finish early."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30brdsVSxhcI"
      },
      "source": [
        "### Challenge 7.1: Rate Limit Handler\n",
        "\n",
        "Create a `RateLimiter` class that:\n",
        "1. Tracks how many requests have been made\n",
        "2. Automatically adds delays to stay under a rate limit\n",
        "3. Handles 429 (Too Many Requests) responses by waiting and retrying\n",
        "\n",
        "```python\n",
        "limiter = RateLimiter(requests_per_minute=30)\n",
        "response = limiter.get(\"https://api.example.com/data\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sIApLC7xhcI"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNY_OW1gxhcI"
      },
      "source": [
        "### Challenge 7.2: Async Movie Collector\n",
        "\n",
        "The synchronous approach is slow because we wait for each request to complete.\n",
        "\n",
        "Create an async version using `aiohttp` that can fetch multiple movies concurrently (while still respecting rate limits).\n",
        "\n",
        "Compare the time to fetch 20 movies with sync vs async approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc_OQO_CxhcI"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "# Hint: You'll need to install aiohttp: pip install aiohttp\n",
        "# And use asyncio to run the async code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bkKaQrtxhcI"
      },
      "source": [
        "### Challenge 7.3: Multi-Source Data Fusion\n",
        "\n",
        "Create a data collection pipeline that:\n",
        "1. Fetches basic movie data from OMDb\n",
        "2. Enriches it with additional data from another source (e.g., Wikipedia API for plot summaries)\n",
        "3. Merges the data based on movie title/year\n",
        "4. Handles cases where data is missing from one source\n",
        "\n",
        "Wikipedia API example:\n",
        "```\n",
        "https://en.wikipedia.org/api/rest_v1/page/summary/Inception_(film)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EieO1NuBxhcI"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNEpl1KsxhcI"
      },
      "source": [
        "---\n",
        "\n",
        "# Summary\n",
        "\n",
        "In this lab, you learned:\n",
        "\n",
        "1. **HTTP Fundamentals**: URLs, status codes, headers\n",
        "2. **curl**: Command-line HTTP requests\n",
        "3. **Python requests**: Programmatic data collection\n",
        "4. **Error handling**: Timeouts, retries, status codes\n",
        "5. **OMDb API**: Real-world movie data\n",
        "6. **BeautifulSoup**: Web scraping when APIs don't exist\n",
        "7. **Data pipelines**: Building reusable collection code\n",
        "\n",
        "## Next Week\n",
        "\n",
        "**Week 2: Data Validation & Quality**\n",
        "\n",
        "The data we collected today is messy! Next week we'll learn:\n",
        "- Schema validation with Pydantic\n",
        "- Data type cleaning\n",
        "- Handling missing values\n",
        "- Quality metrics\n",
        "\n",
        "---\n",
        "\n",
        "## Submission\n",
        "\n",
        "Save your completed notebook and submit:\n",
        "1. This notebook with all cells executed\n",
        "2. The CSV file of movies you collected\n",
        "3. A brief summary (1 paragraph) of what you learned"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
